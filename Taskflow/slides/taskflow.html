<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<meta name="description" conent="An introduction to Taskflow, the C++ task graph library.">
		<meta name="author" content="Martin Nilsson">

		<title>Taskflow</title>


		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">


				<!-- PART I -->
				<!-- INTRODUCTION -->
				<section>
					<h1 class="r-fit-text">Taskflow - A Task Graph Library</h1>
					<p>Subtitle?</p>
					<p>A short introduction</p>
					<p>Parallel programs made easy</p>
					<aside class="notes">
						I'm gonna be talking about computing, because I like computing.<br><br>
						This is a presentation about Taskflow, the task graph library, and why we need such a thing.
					</aside>
				</section>

				<section>
					<h3>The walls</h3>
					<img src="images/cpu-trend.jpg">
					<small><a href="https://www.karlrupp.net/2018/02/42-years-of-microprocessor-trend-data/">https://www.karlrupp.net/2018/02/42-years-of-microprocessor-trend-data/</a></small>

					<aside class="notes">
						For a while computer users enjoyed a steady pace of speed increases.<br><br>
						This kept going until the early 2000's when we hit the walls.<br><br>
						The power and frequency wall in particular.<br><br>
						These are joined by the so called Dennard scaling that says that as the transistors get smaller they use less energy so that the energy density, heat per area, remains roughly constant even though the number of transistors increases.<br><br>
						This stopped being the case somwhere around here, and since peak frequency is highly dependent on the voltage we can push through the transistors and heat is highly depenent on the voltage we hit a point where increasing the frequency and adding more and more tiny transistors lead to unmangeable heat generation.<br><br>
						The famous Moore's law still doing alright but single-threaded performance has not keeping up with the number of transistors and have started to level off.<br><br>
						Frequency not increasing much anymore and CPU / compiler makers are having trouble extracting more instruction level parallelism from straightline code.<br><br>
						To combat this we got more cores.<br><br>
						This means that those of us who remember the times where a new computer would make all programs run faster had to get acustomed to that not being the case anymore and we had to start working to make use all those new transistors hiding behind the second, and third, and ninetysixth core.<br><br>
						The free lunch as over, as the saying goes.
					</aside>
				</section>


				<section>
					<h3>Ways of writing multi-threaded programs</h3>
					<ul>
						<li><p class="fragment semi-fade-out" data-fragment-index="1">Manual threads</p></li>
						<li><p class="fragment semi-fade-out" data-fragment-index="1">Data parallel</p></li>
						<li><p class="fragment semi-fade-out" data-fragment-index="1">Producer / consumer</p></li>
						<li><p class="fragment semi-fade-out" data-fragment-index="1">Pipeline</p></li>
						<li><p>Task graph</p></li>
						<li><p class="fragment semi-fade-out" data-fragment-index="1">Actors / events</p></li>
						<li><p class="fragment semi-fade-out" data-fragment-index="1">Fork-join</p></li>
					</ul>
					<aside class="notes">
						Multiple cores means that we can no longer rely on single-threaded programs, we need to go parallel or concurrent.
						<br><br>
						These mean different things, but for this discussion I'm going to ignore that.
						<br><br>
						Think multi-threaded and we sort of cover what we need.
						<br><br>
						Here are some ways of organizing a multi-threaded program.
						<br><br>
						These are not clear-cut implementation strategies but broad categories.
						<br><br>
						Manual threads means starting a new thread for each task that needs to be done. Think one for audio, one for physics, one for AI, one for graphics, one for IO, and so on in a video game.
						<br><br>
						Data parallel means that we have a serial main thread and whenever we have a large set of elements we need to perform the same operation on then we bring in all the other cores to chrunch the numbers. This is how OpenMP and GPUs work. The classical parallel-for concept.
						<br><br>
						Producer / consumer can be used when we have one part of the program that through some process produces data and another part that reads that data and computes an output. If these are indenpendent then they can be run in parallel on different threads.
						<br><br>
						A pipeline can be though of a chain of producer / consumer pairs where each thread is both a consumer of its input and a producer of the output that becomes the input for the next thread.
						<br><br>
						A task graph is kinda like a branching pipeline where the output produced by one task may be consumed by multiple later tasks. In a task graph we rarely have one thread per task but a pool of worker threads that can be assigned any task that becomes ready to run. A task is typically short-lived while a pipeline is a steady-state construction where data flows through continuously.
						<br><br>
						The actor model models a system of indenpendent concurrently executing entities that listen for events and responds to them with some processing and possibly the generation of new events.
						<br><br>
						Fork-join is a broad categorization that means that that is a main flow of logic that occasionally branches out to parallel computation and that the result from those parallel computations are collected back before the main flow continues. The data parallel model is an example of fork-join.
						<br><br>
						It is possible to combine these, which is what AGX Dynamcis does.
						<br><br>
						Today the focus will be on task graphs, which forms the basis for parallelization in AGX Dynamics and what the Taskflow library provides.
						<br><br>
						Taskflow also does GPU stuff but I'm not going to go into that part today.<br><br>
					</aside>
				</section>

				<section>
					<h3>Task Graph Computing System </h3>
					<p>Instead of chaining function calls together as the program is executed the structure of the computation is defined up-front in a task graph.</p>

					<aside class="notes">
						The "up-front" part is not as rigid as it may sound may expressed like this.
					</aside>
				</section>

				<section>
					<h3>Task Based Parallelism</h3>
					<p>Construct a dependency graph with tasks as nodes.</p>
					<p>Dependencies between tasks represented as edges.</p>
					<p>Execute tasks top-to-bottom.</p>
					<p>Exploit task independence for parallelism.</p>
				</section>

				<section>
					<h3>Example Task Graph</h3>
					<img src="./images/example_task_graph.svg">
					<p>Once Task 1 has completed we can run Task 2 and 4 in parallel.</p>
				</section>

				<section>
					<h3>Static Tasking </h3>
					<p>The simplest form of task graph.</p>
					<p>All tasks are known up front.</p>
					<p>The example on the previous slide is a static task graph.</p>

					<aside class="notes">
						There are different types of task graphs with different types of expressive power.
						<br><br>
						Static tasking is the simplest form. When I said "up-front" earlier this is what I was talking about.
					</aside>
				</section>

				<section data-auto-animate>
					<h3 data-id="title">Fundamental Building Blocks</h3>
					<p data-id="task">A task</p>
					<p data-id="graph">A task graph</p>
					<p data-id="runtime"> A runtime</p>

					<aside class="notes">
						Let's get technical.
						<br><br>
						To realize all of this in an actual application we need three things.
						<br><br>
						Something to represent the tasks to execute. This includes both the work to be performed and metadata such as name, user data and type.
						<br><br>
						Something to represent the dependencies between tasks, the dependency graph.
						<br><br>
						A runtime that can run all tasks in the correct order.
					</aside>
				</section>

				<section data-auto-animate>
					<h3 data-id="title">Fundamental Building Blocks</h3>
					<p data-id="task">A task</p><code>tf::Task</code>
					<br><br>
					<p data-id="graph">A task graph</p> <code>tf::Taskflow</code>
					<br><br>
					<p data-id="runtime">A runtime </p> <code>tf::Executor</code>

					<aside class="notes">
						Taskflow is a C++ library and uses classes to represent these things.
						<br><br>
						All placed within the tf namespace, short for Taskflow.
						<br><br>
						Let's create and run the simplest possible task graph.
					</aside>
				</section>

				<!-- PART II -->
				<!-- SIMPLEST POSSIBLE TASK GRAPH -->

				<section data-auto-animate>
					<h2 data-id="code-title">Simplest Possible Task Graph</h2>
					<pre data-id="simplest-possible-task-graph-animation"><code class="hljs c++" data-trim data-line-numbers="1-4">
						void work()
						{
							std::cout << "Doing work.\n";
						}
					</code></pre>
					<aside class="notes">
						To create a task we need to start with some work to do.
						<br><br>
						Here that work is to print the string "Doing work.".
						<br><br>
						You can imagine any other type of work one might need to do.
					</aside>
				</section>

				<section data-auto-animate>
					<h2 data-id="code-title">Simplest Possible Task Graph</h2>
					<pre data-id="simplest-possible-task-graph-animation"><code class="hljs c++" data-trim data-line-numbers="6-8">
						void work()
						{
							std::cout << "Doing work.\n";
						}

						int main()
						{
						}
					</code></pre>
					<aside class="notes">
						With some work ready to be performed we need to do some setup to arrange for the work to be performed.
						<br><br>
						In this example we do this in main.
					</aside>
				</section>

				<section data-auto-animate>
					<h2 data-id="code-title">Simplest Possible Task Graph</h2>
					<pre data-id="simplest-possible-task-graph-animation"><code class="hljs c++" data-trim data-line-numbers="8">
						void work()
						{
							std::cout << "Doing work.\n";
						}

						int main()
						{
							tf::Taskflow taskflow;
						}
					</code></pre>
					<aside class="notes">
						We create an instance of the Taskflow class to get a task graph in which we can create our task that will call the work function.
					</aside>
				</section>


				<section data-auto-animate>
					<h2 data-id="code-title">Simplest Possible Task Graph</h2>
					<pre data-id="simplest-possible-task-graph-animation"><code class="hljs c++" data-trim data-line-numbers="9">
						void work()
						{
							std::cout << "Doing work.\n";
						}

						int main()
						{
							tf::Taskflow taskflow;
							tf::Task task = taskflow.emplace(work);
						}
					</code></pre>
					<aside class="notes">
						To create a task we don't directly create an instance of the task class and add to the taskflow.
						<br><br>
						Instead we let the taskflow create the task for us by calling emplace.
						<br><br>
						The parameter to emplace is the code we want to have executed when the task is run. This can be anything that is callable with no arguments. Here we use a free function but it could just as well have been a lambda funciton or an object with a call operator.
						<br><br>
						The thing we get back is not the actual task but a handle to it. A handle that is small, cheap to pass around, and safe to copy. It's a pointer, basically. The actual data lives as a node within the task graph.
					</aside>
				</section>

				<section data-auto-animate>
					<h2 data-id="code-title">Simplest Possible Task Graph</h2>
					<pre data-id="simplest-possible-task-graph-animation"><code class="hljs c++" data-trim data-line-numbers="8">
						void work()
						{
							std::cout << "Doing work.\n";
						}

						int main()
						{
							tf::Executor executor;
							tf::Taskflow taskflow;
							tf::Task task = taskflow.emplace(work);
						}
					</code></pre>
					<aside class="notes">
						With the task graph in place we are ready to run it and for this we need the runtime, which in Taskflow is called an executor.
						<br><br>
						In my example I always put it high in main to signal that this is a heavy-weigth, long-lived, and shared resource. It is not meant to be created every time we want to run a task graph. Instead we should create one at startup and reuse it throught the application's life time.
						<br><br>
						This is where the worker threads are spawned.
					</aside>
				</section>

				<section data-auto-animate>
					<h2 data-id="code-title">Simplest Possible Task Graph</h2>
					<pre data-id="simplest-possible-task-graph-animation"><code class="hljs c++" data-trim data-line-numbers="11">
						void work()
						{
							std::cout << "Doing work.\n";
						}

						int main()
						{
							tf::Executor executor;
							tf::Taskflow taskflow;
							tf::Task task = taskflow.emplace(work);
							executor.run(taskflow).wait();
						}
					</code></pre>
					<aside class="notes">
						Now we are ready to do some work for real.
						<br><br>
						Executor.run will cause the runtime to start running tasks using the worker threads. We can chose to either keep doing other things in the main thread or wait for the tasks to finish executing. Since we have nothing else to do in this example we wait.
						<br><br>
						I have not yet found a way to make the main thread participate in the task work, which is a bit limiting given that in AGX Dynamics we always run user supplied event listeners in the main thread. There is more to Taskflow that I haven't explored yet it is possible that this can be solved.
					</aside>
				</section>

				<section data-auto-animate>
					<h2 data-id="code-title">Simplest Possible Task Graph</h2>
					<pre data-id="simplest-possible-task-graph-animation"><code class="hljs c++" data-trim data-line-numbers>
						void work()
						{
							std::cout << "Doing work.\n";
						}

						int main()
						{
							tf::Executor executor;
							tf::Taskflow taskflow;
							tf::Task task = taskflow.emplace(work);
							executor.run(taskflow).wait();
						}
					</code></pre>
					<aside class="notes">
						And there you have it, the smallest possible task graph in Taskflow.
						Though we're missing some header inclues.
					</aside>
				</section>

				<section data-auto-animate>
					<h2 data-id="code-title">Simplest Possible Task Graph</h2>
					<pre data-id="simplest-possible-task-graph-animation"><code class="hljs c++" data-trim data-line-numbers="1,2"><script type="text/template">
						#include "taskflow/taskflow.hpp"
						#include <iostream>

						void work()
						{
							std::cout << "Doing work.\n";
						}

						int main()
						{
							tf::Executor executor;
							tf::Taskflow taskflow;
							tf::Task task = taskflow.emplace(work);
							executor.run(taskflow).wait();
						}
					</script></code></pre>
					<aside class="notes">
						This can compile and run. But we also want pretty picture, like the task graph example we saw in the introduction.
					</aside>
				</section>

				<section data-auto-animate>
					<h2 data-id="code-title">Simplest Possible Task Graph</h2>
					<pre data-id="simplest-possible-task-graph-animation"><code class="hljs c++" data-trim data-line-numbers="16-19"><script type="text/template">
						#include "taskflow/taskflow.hpp"
						#include <iostream>
						#include <fstream>

						void work()
						{
							std::cout << "Doing work.\n";
						}

						int main()
						{
							tf::Executor executor;
							tf::Taskflow taskflow;
							tf::Task task = taskflow.emplace(work);
							executor.run(taskflow).wait();
							taskflow.name("Simplest Possible Task Graph");
							task.name("A Lonely Task");
							std::ofstream file("simplest_possible_task_graph.dot");
							taskflow.dump(file);
						}
					</script></code></pre>
					<aside class="notes">
						Let's give the graph and task a name and dump them to a DOT file. It won't be all that useful for this minimal example but is a great help when build larger real-world graphs.
					</aside>
				</section>

				<section>
					<h3>SIMPLEST POSSIBLE TASK GRAPH</h3>
					<img src="./images/simplest_possible_task_graph.svg">
					<aside class="notes">
						And this is what it looks like, after some edits to get a dark-mode variant.
						<br><br>
						But sometimes we need more than one task, so let's make a new example where we create a few of them
					</aside>
				</section>

				<!-- PART III -->
				<!-- TASK DEPENDENCIES -->

				<section>
					<h3>TASK DEPENDENCIES</h3>
					<pre><code class="hljs c++" data-trim data-line-numbers="|2|1|3-7|3|6|"><script type="text/template">
						auto [t1, t2, t3, t4, t5, t6] = taskflow.emplace(
							[](){}, [](){}, [](){}, [](){}, [](){}, [](){});
						t1.precede(t2, t3, t4);
						t1.precede(t2, t3);
						t3.precede(t4, t5);
						t6.succeed(t2, t4, t5);
					</script></code></pre>
					<p class="fragment fade-in"><img src="./images/example_task_graph.svg"></p>
					<aside class="notes">
						From now on I won't show entire code examples since they won't fit on a slide anymore. Instead I'll show only enough to get the point accross.
						<br><br>
						I'll also use an empty lambda whenever the work done doesn't matter for the presentation. Here we have a whole bunch of them being passed to emplace.
						<br><br>
						The effect of this is that we get the same number of tasks handles back in a tuple, which we can use structured bindings to unpack into a  bunch of variables, here named t1, t2, and so on up to t6.
						<br><br>
						Dependencies are created using the precede and succeed Task member functions. precede makes the task on the left precede, i.e. happen before, the tasks on the right. succeed, on the other hand, makes the task happen after the parameter tasks.
						<br><br>
						Looking at the resuling dependency graph we get this familiar diagram from the start of the presentation.
						<br<br>
						It doesnt matter if we do t1.precede(t2) or t2.succeede(t1), both variants describe the same dependency. The only difference is that it is easy to pass many parameters to a single function so when a node has more input dependencies than output then I tend to use succeed and when it has more output dependencies then I tend to use precede.
					</aside>
				</section>

				<!-- PART IV -->
				<!-- Dynamic Tasks -->

				<section>
					<h3>DYNAMIC TASKS</h3>
					<p>Tasks that might not exist.</p>
					<aside class="notes">
						We don't always know ahead of time whether a particular task will need to be run. For this case Taskflow provides dynamics tasks. A dynamic task is one that may contain child tasks and those tasks are created at runtime when the parent task is run. This makes it possible for earlier tasks to control what later tasks does.
						<br><br>
						Let's first look at a trivial example, and then one a smitten closer to a real-world use-case.
					</aside>
				</section>

				<section>
					<h3>Dynamic tasks</h3>
					<pre><code class="hljs c++" data-trim data-line-numbers><script type="text/template">
						tf::Task parent = taskflow.emplace(
							[](tf::Subflow& subflow) {
								tf::Task child = subflow.emplace([]() {});
							});
					</script></code></pre>
					<aside class="notes">
						We tell Taskflow that a task is dynamic by providing a callback that takes a Subflow parameter. A subflow is similar to a taskflow in that we can emplace new tasks in it. The tasks we get back are just like any other and we can give then name add depdencies, and so on. We can create any number of child tasks, and the child tasks can themselves be dynamic tasks.
						<br><br>
						What's important to realize is that while tasks created on a taskflow object are  created before the task graph is executed, the tasks in the sublow are created while execution is ongoing. Some tasks may already have finished by the time the parent task is executed and the child task created.
						<br><br>
						Another important thing is that the child task is run immediately after the parent callback returns. This means that any task that has a dependency on the parent task also has an transitive dependency on the child task.
						<br><br>
						The child task is "inside" the parent task.
					</aside>
				</section>

				<section>
					<h3>DYNAMIC TASKS</h3>
					<pre><code class="hljs c++" data-trim data-line-numbers="|1|4|6,7|8-10|13-15|18-26|29-34|36-44|46-48|50-57"><script type="text/template">
						class Space
						{
						public:
							void emplaceTasks(tf::Taskflow& taskflow);

							void broadPhase();
							void nearPhase(tf::Subflow& subflow);
							void nearPhaseSphereSphere();
							void nearPhaseSphereBox();
							void nearPhaseBoxBox();

						private:
							int m_numSphereSperePairs {0};
							int m_numSphereBoxPairs {0};
							int m_numBoxBoxPairs {0};
						};

						void Space::emplaceTasks(tf::Taskflow& taskflow)
						{
							tf::Task broadPhaseTask = taskflow.emplace(
								[this]() { broadPhase(); });

							tf::Task nearPhasesTask = taskflow.emplace(
								[this](tf::Subflow& subflow) { nearPhase(subflow); });

							broadPhaseTask.precede(nearPhasesTask);
						}

						void Space::broadPhase()
						{
							m_numSphereSperePairs = 1;
							m_numSphereBoxPairs = 0;
							m_numBoxBoxPairs = 1;
						}

						void Space::nearPhase(tf::Subflow& subflow)
						{
							if (m_numSphereSperePairs > 0)
								subflow.emplace([this]() { nearPhaseSphereSphere(); });
							if (m_numSphereBoxPairs > 0)
								subflow.emplace([this]() { nearPhaseSphereBox(); })
							if (m_numBoxBoxPairs > 0)
								subflow.emplace([this]() { nearPhaseBoxBox(); })
						}

						void Space::nearPhaseSphereSphere(){}
						void Space::nearPhaseSphereBox(){}
						void Space::nearPhaseBoxBox(){}

						int main()
						{
							Space space;
							tf::Executor executor;
							tf::Taskflow taskflow;
							space.emplaceTasks(taskflow);
							executor.run(taskflow).wait();
						}

					</script></code></pre>
					<aside class="notes">
						Let's move to a larger example, one that well need to page through bit by bit. I'm using a somewhat more real-world example here, with a two-phase collision detection implementation.
						<br><br>
						We have a class named Space that handles all collision-detection tasks.
						<br><br>
						It has en emplaceTasks function that is kind analogus to our current createUpdateTask.
						<br><br>
						This function will create two tasks, one for broad-phase and one for narrow-phase. The broadPhase function is just like all the other work callbacks we've seen: a function with no parameters.
						In our example it finds all shape pairs that are close to each other and groups them by shape types.
						The nearPhase function is different. It takes a Subflow parameter. This is what tells Taskflow that this task is not a static task but a dynamic one. A task that can create internal child tasks.
						<br><br>
						The near-phase task will create a child task for every shape type pair, but only if the broad-phase found at least one shape pair with those types.
						<br><br>
						Space has some internal state. Here we simplify it to just home may shape pairs there are for each type-pair. It is the responsibility of broad-phase to update these values.
						<br><br>
						Let's have a look at emplaceTasks. It's pretty simple. It creates two tasks in the given Taskflow, one for broad-phase and one for near-phase. We could have placed the entire implementation of these two functions within the lambdas, but I find it more readable to keep the implementation in their own functions and have the callback we give to Taskflow just call the  class member function, passing on the parameters. Notice that when creating the near-phase task we pass a lambda that takes a Subflow parameter, which we pass on to the member function. Lastly we make sure the narrow-phase task isn't allowed to start until the broad-phase task has completed.
						<br><br>
						The broadPhase implementation is just a placeholder here. Pretend we found some  sphere-sphere pairs and some box-box pairs, but no sphere-box pairs.
						<br><br>
						Here comes the interesting bit. The parent task of the near-phase subflow checks the result of the broad-phase and creates only the tasks that have anything to do. The others are simply skipped. Rember that in our example we have sphere-sphere and box-box pairs but no sphere-box pair.
						<br><br>
						The actual near-phase computation we don't care about here.
						<br><br>
						The implementation of main shouldn't present any surprises. We create an instance of our Space class, an executor and a Taskflow as we always do, let the Space instance create it's tasks in the Taskflow and then pass it to the executor to run it.
					</aside>
				</section>

				<section>
					<h3>Dynamic Tasks</h3>
					<img src="images/work_if_needed.svg">
					<aside class="notes">
						The result of all this is a task graph with a broad-phase static task and a near-phase subflow with two near-phase child tasks. Notice that here there is no sphere-box task in the near-phase subflow. In a working simulation the set of tasks could change from time-step to time-step.
						<br><br>
						This is an important point to be aware of. The child tasks doesn't exist until they are creaatd during task graph execution so there is no way to create one of these visualizations of the entire task graph with all possible child tasks. The visualization only captures one specific execution of the task graph.
					</aside>
				</section>

			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>